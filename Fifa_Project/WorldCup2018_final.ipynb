{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from tweepy import Stream\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import nltk\n",
    "import nltk.stem\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import operator\n",
    "import folium\n",
    "from folium import plugins\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import emoji\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J\n",
    "consumer_key = 'awImzJ7cQtYMj5jbeeWenLe8R'\n",
    "consumer_secret = 'Rnr5qv5DRlhelrLPyF1j1AWLi5aE139k1nd074gaiiEOXiHZfi'\n",
    "access_token = '999278084774866945-KxBvG48iodCgSj5tDS1El5u7r2lAXX8'\n",
    "access_secret = 'AXGP5SHhpbJuCLVNbRU5yh6fOIwvxLTZOVdBWysWYbG6L'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#J2\n",
    "cnsumer_key = 'pEKQsmgPg9YaetPhGTt7z9tw1'\n",
    "consumer_secret = 'SHHnGWYIld5eCxWWqUyq7aApedVA4dF1FjvWekbszajcc6Ubdc'\n",
    "acces_token = '999278084774866945-MjhQGh9zdokdMdCAtkegityA95eLLyt'\n",
    "acces_secret = '8AAMdWirUtvx99rM3XaeEJ3cnh2B03rvRJeMQB11H5GJc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R\n",
    "consumer_key = 'qbKANPvBND4cDKzRy7dVv7tFM'\n",
    "consumer_secret = '9GgohQQOuujfVB90csXGHakbI4wnht09DxwqF0Tc6Qjh21U9uc'\n",
    "access_token = '999278723659632641-J2BeDRgUL6pyXgxHWA0pscDPuKLALar'\n",
    "access_secret = '7bdrHnvtEnVSXc71llbbONW8DMLmCw62Mp6FuSjk8rq3u'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R2\n",
    "consumer_key = 'lkJEhnBhutbMfUoJnH0BIQyqD'\n",
    "consumer_secret = 'v1cbGUgzUGi4q0TAiBhB53pglnJCAcVKv9T12Ftz4ANLGZdkmp'\n",
    "access_token = '999278723659632641-2mgorBfuXIXYODLzYU6fX43EfT2qFNi'\n",
    "access_secret = 'ffVohG14AR0zMrudA60S49X9Y0vZjzUUj4xMScOTmMb6B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#R3\n",
    "consumer_key = 'IYifTIDZ1tlcUu1vdPmI2wMYm'\n",
    "consumer_secret = 'QaxzTwaECgGugwFb4VHl2aGOSPDcgAo0hNVG0je3gpZ2rbsjCp'\n",
    "access_token = '999278723659632641-AEQAFJdwVVBpMa4SsXLqRN34Fud0bQJ'\n",
    "access_secret = 'KwdGZYFMRuoZ8uHlJNghqMVHscMBEaMl9k1uzlFbUxIKn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"fifa.log\",level=logging.DEBUG,format=\"%(asctime)s | %(levelname)s | %(message)s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyListener(StreamListener):\n",
    " \n",
    "    def on_data(self, data):\n",
    "        try:\n",
    "            \n",
    "            with open('WorldCup.json', 'a') as f:\n",
    "                f.write(data)\n",
    "                logging.debug(data)\n",
    "                #print(data)\n",
    "                return True\n",
    "        except BaseException as e:\n",
    "            print(\"Error on_data: %s\" % str(e))\n",
    "        return True\n",
    " \n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_polygone_saint_petersbourg = [29.497997, 59.701434, 30.662548, 60.197935]\n",
    "geo_polygone_samara = [49.994802, 53.088547, 50.383159, 53.414352]   \n",
    "geo_polygone_saransk = [45.062645, 54.156444, 45.290509, 54.244795] \n",
    "geo_polygone_kazan = [48.849433, 55.685018, 49.284766, 55.915044] \n",
    "geo_polygone_lekaterinbourg = [60.434298, 56.675458, 60.840805, 56.940268] \n",
    "geo_polygone_moscou = [36.737227, 55.145210, 38.020595, 56.047568] \n",
    "geo_polygone_nijni_novgorod = [43.745447, 56.177553, 44.103876, 56.397831]\n",
    "geo_polygone_volgograd = [44.414738, 48.454773, 44.741175, 48.875449]\n",
    "geo_polygone_rostov_sur_le_don = [39.410991, 47.137967, 39.849071, 47.380294]\n",
    "geo_polygone_sotchi = [39.639782, 43.539785, 39.805785, 43.659389]\n",
    "geo_polygone_kaliningrad = [20.302802, 54.639647, 20.631730, 54.786058]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\logging\\__init__.py\", line 994, in emit\n",
      "    stream.write(msg)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 366-371: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-7-644e6714ee72>\", line 8, in <module>\n",
      "    or geo_polygone_sotchi or geo_polygone_kaliningrad)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\", line 450, in filter\n",
      "    self._start(async)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\", line 364, in _start\n",
      "    self._run()\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\tweepy\\streaming.py\", line 250, in _run\n",
      "    verify=self.verify)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 494, in request\n",
      "    prep = self.prepare_request(req)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 437, in prepare_request\n",
      "    hooks=merge_hooks(request.hooks, self.hooks),\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\requests\\models.py\", line 309, in prepare\n",
      "    self.prepare_auth(auth, url)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\requests\\models.py\", line 540, in prepare_auth\n",
      "    r = auth(self)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\requests_oauthlib\\oauth1_auth.py\", line 80, in __call__\n",
      "    unicode(r.url), unicode(r.method), r.body or '', r.headers)\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\oauthlib\\oauth1\\rfc5849\\__init__.py\", line 314, in sign\n",
      "    ('oauth_signature', self.get_oauth_signature(request)))\n",
      "  File \"C:\\Users\\joudj\\Anaconda3\\lib\\site-packages\\oauthlib\\oauth1\\rfc5849\\__init__.py\", line 135, in get_oauth_signature\n",
      "    log.debug(\"Collected params: {0}\".format(collected_params))\n",
      "Message: \"Collected params: [('delimited', 'length'), ('oauth_nonce', '164507383559214769401528932916'), ('oauth_timestamp', '1528932916'), ('oauth_version', '1.0'), ('oauth_signature_method', 'HMAC-SHA1'), ('oauth_consumer_key', 'IYifTIDZ1tlcUu1vdPmI2wMYm'), ('oauth_token', '999278723659632641-AEQAFJdwVVBpMa4SsXLqRN34Fud0bQJ'), ('track', '—Ñ—É—Ç–±–æ–ª,–§–ò–§–ê,–†–æ—Å—Å–∏—è 2018,–†–æ—Å—Å–∏—è2018,–ö—É–±–æ–∫ –º–∏—Ä–∞,FIFAFanFest,WM2018,Russia2018WorldCup,World Cup 2018 Russia,World Cup Saint Petersburg,FIFAFanMatch,–ß–µ–º–ø–∏–æ–Ω–∞—Ç –º–∏—Ä–∞,–ß–ú2018,TeamRussia,–ö–æ–º–∞–Ω–¥–∞ –†–æ—Å—Å–∏—è'), ('locations', '29.4980,59.7014,30.6625,60.1979')]\"\n",
      "Arguments: ()\n"
     ]
    }
   ],
   "source": [
    "twitter_stream = Stream(auth, MyListener())\n",
    "twitter_stream.filter(track=[\"—Ñ—É—Ç–±–æ–ª\", \"–§–ò–§–ê\", \"–†–æ—Å—Å–∏—è 2018\", \"–†–æ—Å—Å–∏—è2018\", \"–ö—É–±–æ–∫ –º–∏—Ä–∞\",\"FIFAFanFest\",\n",
    "                             \"WM2018\",\"Russia2018WorldCup\",\"World Cup 2018 Russia\",\"World Cup Saint Petersburg\",\n",
    "                             \"FIFAFanMatch\",\"–ß–µ–º–ø–∏–æ–Ω–∞—Ç –º–∏—Ä–∞\",\"–ß–ú2018\",\"TeamRussia\",\"–ö–æ–º–∞–Ω–¥–∞ –†–æ—Å—Å–∏—è\"],\n",
    "                      locations = geo_polygone_saint_petersbourg or geo_polygone_samara or geo_polygone_saransk \n",
    "                      or geo_polygone_kazan or geo_polygone_lekaterinbourg or geo_polygone_moscou \n",
    "                      or geo_polygone_nijni_novgorod or geo_polygone_volgograd or geo_polygone_rostov_sur_le_don \n",
    "                      or geo_polygone_sotchi or geo_polygone_kaliningrad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "for line in open('fifa.json', 'r', encoding=\"utf8\"):\n",
    "    tweets.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_tweets_en = []\n",
    "list_of_tweets_es = []\n",
    "list_of_tweets_fr = []\n",
    "list_of_tweets_ru = []\n",
    "coord_en = []\n",
    "coord_es = []\n",
    "coord_fr = []\n",
    "coord_ru = []\n",
    "\n",
    "def store_lang(text_lang, text_lang2, liste, list_coord, i):\n",
    "    for x in range(i):\n",
    "        if tweets[x].get(\"lang\") == text_lang and text_lang2 :\n",
    "            liste.append([tweets[x][\"_id\"],tweets[x][\"text\"]])\n",
    "            list_coord.append(tweets[x]['geo']['coordinates'])\n",
    "            \n",
    "store_lang(\"en\",\"uk\",list_of_tweets_en,coord_en,len(tweets))\n",
    "store_lang(\"es\",\"es\",list_of_tweets_es,coord_es,len(tweets))\n",
    "store_lang(\"fr\",\"fr\",list_of_tweets_fr,coord_fr,len(tweets))\n",
    "store_lang(\"ru\",\"und\",list_of_tweets_ru,coord_ru,len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_id_en = []\n",
    "list_of_id_ru = []\n",
    "list_of_id_fr = []\n",
    "list_of_id_es = []\n",
    "\n",
    "def preprocess_id(list_dep,list_arriv):\n",
    "    for ele in list_dep:\n",
    "        liste=list()\n",
    "        for i in [0]:\n",
    "            e=ele[i]\n",
    "            e = str(e)\n",
    "            e = e.split(\"'\")\n",
    "            e = e[3]\n",
    "            liste.append(e)\n",
    "        list_arriv.append(liste)\n",
    "    for e in list_arriv:\n",
    "        e = str(e)\n",
    "        e = e.replace(\"[\",\"\")\n",
    "        e = e.replace(\"]\",\"\")\n",
    "    return list_arriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_id_en = preprocess_id(list_of_tweets_en,list_of_id_en)\n",
    "list_of_id_es = preprocess_id(list_of_tweets_es,list_of_id_es)\n",
    "list_of_id_fr = preprocess_id(list_of_tweets_fr,list_of_id_fr)\n",
    "list_of_id_ru = preprocess_id(list_of_tweets_ru,list_of_id_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_good_id_en = []\n",
    "list_good_id_ru = []\n",
    "list_good_id_fr = []\n",
    "list_good_id_es = []\n",
    "\n",
    "def good_id(list_dep,list_arriv):\n",
    "    for e in list_dep:\n",
    "        e = str(e)\n",
    "        e = e.replace(\"[\",\"\")\n",
    "        e = e.replace(\"]\",\"\")\n",
    "        e = e.replace(\"'\",\"\")\n",
    "        list_arriv.append(e)\n",
    "    return list_arriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_good_id_en = good_id(list_of_id_en,list_good_id_en)\n",
    "list_good_id_ru = good_id(list_of_id_ru,list_good_id_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_all_tweets_en = []\n",
    "list_all_tweets_es = []\n",
    "list_all_tweets_fr = []\n",
    "list_all_tweets_ru = []\n",
    "for ele in list_of_tweets_en:\n",
    "     list_all_tweets_en.append(ele[1])\n",
    "for ele in list_of_tweets_es:\n",
    "     list_all_tweets_es.append(ele[1])\n",
    "for ele in list_of_tweets_fr:\n",
    "     list_all_tweets_fr.append(ele[1])\n",
    "for ele in list_of_tweets_ru:\n",
    "     list_all_tweets_ru.append(ele[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'So long St. Petersburg. You were grand. Now for‚Ä¶ https://t.co/UpfQa02MHI'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_all_tweets_en[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerword(liste):\n",
    "    low = []\n",
    "    for e in liste:\n",
    "        e = e.lower()\n",
    "        low.append(e)\n",
    "    return low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_low_en = lowerword(list_all_tweets_en)\n",
    "list_low_es = lowerword(list_all_tweets_es)\n",
    "list_low_fr = lowerword(list_all_tweets_fr)\n",
    "list_low_ru = lowerword(list_all_tweets_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_en = dict(zip(list_good_id_en, list_low_en))\n",
    "dict_es = dict(zip(list_good_id_es, list_low_es))\n",
    "dict_fr = dict(zip(list_good_id_fr, list_low_fr))\n",
    "dict_ru = dict(zip(list_good_id_ru, list_low_ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatiz(chaine):\n",
    "    lemma = WordNetLemmatizer()\n",
    "    lem = []\n",
    "    lem2 = chaine.split(\" \")\n",
    "    for e in lem2:\n",
    "        e = e.replace(\"::\",\" \")\n",
    "        e = e.replace(\"@\",\" \")\n",
    "        e = e.replace(\":\",\" \")\n",
    "        e = e.replace(\"‚Ä¶\",\" \")\n",
    "        e = re.sub(\",|&|;|\\.\", \"\", e)\n",
    "        e = re.sub(\"\\'|\\‚Äô|\\‚Äù|\\‚Äú|\\‚Äî|\\/\", \" \", e)\n",
    "        e = re.sub(\"\\\"|\\¬ª|\\¬´|\\]|\\[|\\:|\\#\",\"\", e)\n",
    "        e = re.sub(\"\\'m|\\'s|\\'t\", \"\", e)\n",
    "        e = re.sub(\"[0-9]\", \"\", e)\n",
    "        e = re.sub(\"\\s+\", \" \", e)\n",
    "        e = re.sub(\"http.*\",\"\",e)\n",
    "        e = re.sub(\"\\!|\\?|\\*\", \"\", e)\n",
    "        e2 = emoji.demojize(e)\n",
    "        lem.append(lemma.lemmatize(e2))\n",
    "        \n",
    "    return lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11322"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_low_en) + len(list_low_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_en=nltk.stem.SnowballStemmer('english')\n",
    "stemmer_fr=nltk.stem.SnowballStemmer('french')\n",
    "stemmer_es=nltk.stem.SnowballStemmer('spanish')\n",
    "stemmer_ru=nltk.stem.SnowballStemmer('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stw(liste,liste_stw):\n",
    "    for e in liste:\n",
    "        if e in liste_stw:\n",
    "            liste.remove(e)\n",
    "    return liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stw_en=stopwords.words('english')\n",
    "stw_fr=stopwords.words('french')\n",
    "stw_es=stopwords.words('spanish')\n",
    "stw_ru=stopwords.words('russian')\n",
    "for letter in range(97,123):\n",
    "    stw_en.append(chr(letter))\n",
    "    stw_es.append(chr(letter))\n",
    "    stw_fr.append(chr(letter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_tweet(liste,stemmer):\n",
    "    return_list = []\n",
    "    for e in liste:\n",
    "        return_list.append(stemmer.stem(e))\n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionnaire anglais => sentiments : mots du champ lexical du sentiment\n",
    "dict_sentiment_en = {\"joy\" : \"üòÄ,üòÅ,üòÉ,üòù,üòÇ,ü§£,üòä,üëç,üèÜ,joy,standing,happiness,jubilation,cheerfulness,euphoria,rejoicing,serenity,bliss,joyfulness,exaltation,gaiety,joyful,delight,ineffable,radiant,voluptuousness,laugh,laughing,carried,hallelujah,kindness,delight,euphoric,exultation,feast,hilarity,enjoyment,cheer,joyous,applause,exult,maternity,baby,paternity,beaming,skip,buddy,friend,clamor,hold,elan,wonder,filled,frolicking,happy,peace,fullness,comfort,fills,sharing,celebration,success,heaven,blooming,enlightenment,freedom,fun,dancing,relaxation,distraction,entertainment,playfulness,fun,joviality,joyfulness,play,holiday,joke,fun,laugh,buzz,synthesizer,sing,travel,fairy,clap,victory,share,zabivaka,win,game,fest,playing,madness,phenomenal,thankful,happy,celebrate,cup,bar,win\".split(\",\"),\n",
    "                     \"hope\" : \"üôè,forgive,pray,optimistic,positivity,positive,confidence,future,recklessness,idealism,realism,happiness,joy,intelligence,vitality,progress,calm,confident,believe,dynamic,caring,perseverance,comfortable,relaxation,euphoria,optimum,option,possible,relief,forgetfulness,abstraction,relax,want,hope,power,success,opportunity,future,innovation,perfect,confident,enthusiastic,ambition,mad,vain,wait,release,glow,courage,best,victory,desire,give,wish,return,last,time,resigned,disillusionment,concerns,reborn,dreams,faith,injury,perspective,podium,talent,purpose,confidence,healing,give,season,decisive,selected,luck,caress,conciliation,keeper,unwavering,find,save,time,life,winning,resurrect,aspiration,assurance,consolation,belief,creed,time,delivery,flattering,pause,forecast,next,project,promise,expectation,illusion,pandora,life,mercy,promise,probability,certainty,desire,gain,flag,god,light,vain,progress,belief,lure,omen,presumption,grief,enthusiasm,patient,consolation,fullness,insurance,consoling,commitment,reliability,infant,intuition,forecast,project,feeling,safety,wishes,bless,fans,ahead\".split(\",\"),\n",
    "                     \"love\" :  \"üòç',‚ù§Ô∏è,üíò,üíï,üòò,üòó,remarkable,friendship,teammate,affection,passion,love,kiss,commitment,beauty,compassion,attraction,happiness,pleasure,heart,romantic,worship,singing,fraternal,heartfelt,devotion,god,fidelity,flame,altruism,soul,sorrow,song,wife,husband,affair,loyalty,sacrifice,friendly,juliet,ideal,friends,amor,hug,girl,madly,mother,mum,admiration,generosity,respect,statement,fervor,infinite,beautiful,son,adorable,dedication,consumer,fusion,sister,ange,express,child,exaltation,wonderful,unite,madly,passion,mutual,passion,frenzy,delirium,passion,spectacular,addiction,hobbies,enthusiasm,emotion,inclination,fire,romantic,magnificent,excess,fire,mystery,passion,photography,poetry,enthusiastic,flame,sensual,delusion,crush,spirit,enthusiasm,insatiable,leisure,nativity,relationship,gardening,dedication,warmth,exalted,fury,youth,sensual,fiery,heart,wild,devotion,exhilarating,female,flatter,frantic,shameful,business,budding,meet,spend,destructive,unconsciousness,sublime,bigotry,love,soul,appetite,burning,flesh,consume,devour,player,sudden,life,choral,conviction,passion,desire,instinct,hobby,sentimental,talented,bright,collect,daydreaming,fanatical,adoration,affection,panic,agitation,overflow,momentum,excitement,enthusiasm,ecstasy,fever,obstinacy\".split(\",\"),\n",
    "                     \"sadness\" : \"üíß,üòø,üôÄ,üò´,üò®,üò≤,üòû,üò©,üò¢,üò™,üò∑,üò≠,üíî,üò¶,sadness,trouble,goodbye,melancholy,grief,mourning,despair,nostalgia,disgust,pain,tear,sad,bitterness,discouragement,loneliness,sadness,melancholy,depression,affliction,lassitude,desolation,misfortune,languor,resignation,cockroach,despondency,regret,crying,bitter,worry,compassion,consolation,rancor,spree,deep,acedial,blues,glaucous,farewell,tearing,despite,disgust,overwhelmed,shot,lament,gloomy,cloud,aggression,anguish,boredom,disappointment,despair,disgruntled,displeasure,fatigue,frustration,gloomy,grief,loneliness,miserable,unhappiness,painful,despair,collapsed,inconsolable,indefinable,evil,misanthropy,misery,poverty,laziness,isolation,malaise,moral,rancor,despondency,sadness,boredom,dreadfulness,dreariness,embarrassment,festering,greed,hypochondria,unspeakable,dreary,monotonous,recollection,stunner,torment,uniformity,suicide,poor,homeless,cemetery,creeping,grievousness,grievous,old,age,shabby,pity,pessimistic,pessimism,will,defeatism,melancholy,skepticism,bitter,morbid,philosophical,resignation,subjective,bitterness,disgust,fatalism,romanticism,symbolism,conception,romantic,suicide,individualism,denouement,renunciation,negative,decadence,alarmism,catastrophism,disbelief,disquiet,neurasthenia,nostalgia,worry,tracassin,tragic,misery,unemployment,suicide,poor,dead,death,cemetery,tears,injustice,shabby,pitiful,pity,sick,lose\".split(\",\"),\n",
    "                     \"anger\" : \"üò†,üò§,üëé,üñï,üò°,üí¢,üî¥,üëä,‚ùó,üíÄ,üòí,fussing,cussing,nagging,skull,indignation,rage,irritation,choleric,resentment,fury,hate,anger,rancor,revenge,fury,ire,wrath,frustration,pride,despite,exasperation,furious,annoyance,revolt,fury,enmity,contempt,rancor,despondency,angry,disgust,irascibility,expletive,bitterness,aggression,impatience,threat,animosity,explosion,humiliation,violence,anger,desperation,violent,blast,avenge,stumbles,amazement,aggression,manifesting,guilt,lock,elimination,injustice,irascible,chastise,madness,dejure,incite,excite,thunder,fulminant,irritate,master,shit,deaf,rager,affront,annoyance,bubble,seizure,unleashing,irritability,irritant,outraged,repressed,vehement,acceptance,disarm,spill,pour,out,howl,impulse,indignation,exit,terrible,hostility,avenger,beating,dishonesty,end,disgrace,evil,fear,insulted,insulting,offense,overt,punish,outrage,sin,sting,greed,burning,anger,bewilderment,erupting,fever,quivering,frenzy,harassment,intemperance,intensity,interjection,malevolence,club,threatening,firecracker,provoked,spiteful,tension,violent,snarling,threatening,punk,assault,combative,hateful,provocative,aggressively,hostile,conqueror,haughty,insolent,intolerant,intruder,tone,passive,sarcastic,brutal,adversary,temperament,pitbull,bellicose,nagging,catchy,acerbic,eager,sour,brawler,battler,angry,belligerent,beatificer,quarrelsome,contentious,cruel,dangerous,dangerous,fight,fighter,frustrated,furious,irate,insecure,impetuous,irascible,malicious,martial,offending,offensive,provoking,pugnacious,raging\".split(\",\"),\n",
    "                     \"neutral\":\"\",\n",
    "                     \"joy/hope\":\"\",\n",
    "                     \"love/sadness\":\"\"\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sentiment_ru = {\"joy\": \"üòÄ,üòÅ,üòÉ,üòù,üòÇ,ü§£,üòä,üëç,üèÜ,—Ä–∞–¥–æ—Å—Ç—å,—Å—Ç–æ—è,—Å—á–∞—Å—Ç—å–µ,–ª–∏–∫–æ–≤–∞–Ω–∏–µ,–±–æ–¥—Ä–æ—Å—Ç—å,—ç–π—Ñ–æ—Ä–∏—è,—Ä–∞–¥–æ—Å—Ç—å,–±–µ–∑–º—è—Ç–µ–∂–Ω–æ—Å—Ç—å,–±–ª–∞–∂–µ–Ω—Å—Ç–≤–æ,—Ä–∞–¥–æ—Å—Ç—å,–≤–æ—Å—Ç–æ—Ä–≥,–≤–µ—Å–µ–ª—å–µ,—Ä–∞–¥–æ—Å—Ç—å,–≤–æ—Å—Ç–æ—Ä–≥,–Ω–µ–≤—ã—Ä–∞–∑–∏–º—ã–π,—Å–∏—è—é—â–∏–π,—Å–ª–∞–¥–æ—Å—Ç—Ä–∞—Å—Ç–Ω—ã–π,—Å–º–µ—Ö,—Å–º–µ—Ö,–Ω–µ—Å—É—Ç,–∞–ª–ª–∏–ª—É–π—è,–¥–æ–±—Ä–æ—Ç–∞,–≤–æ—Å—Ç–æ—Ä–≥,—ç–π—Ñ–æ—Ä–∏—è,–ª–∏–∫–æ–≤–∞–Ω–∏–µ,–ø—Ä–∞–∑–¥–Ω–∏–∫,–≤–µ—Å–µ–ª—å–µ,–Ω–∞—Å–ª–∞–∂–¥–µ–Ω–∏–µ,—Ä–∞–¥–æ—Å—Ç—å,—Ä–∞–¥–æ—Å—Ç–Ω–∞—è,–∞–ø–ª–æ–¥–∏—Å–º–µ–Ω—Ç—ã,—Ä–∞–¥—É–π—Ç–µ—Å—å,–º–∞—Ç–µ—Ä–∏–Ω—Å—Ç–≤–æ,—Ä–µ–±–µ–Ω–æ–∫,–æ—Ç—Ü–æ–≤—Å—Ç–≤–æ,—Å–∏—è—è,–ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å,–ø—Ä–∏—è—Ç–µ–ª—å,–¥—Ä—É–≥,—à—É–º–∏—Ö–∞,–¥–µ—Ä–∂–∞—Ç—å,–ø–æ—Ä—ã–≤,—É–¥–∏–≤–ª–µ–Ω–∏–µ,–Ω–∞–ø–æ–ª–Ω–µ–Ω–Ω–∞—è,—Ä–µ–∑–≤–∏–ª—Å—è,—Å—á–∞—Å—Ç–ª–∏–≤–∞—è,–º–∏—Ä,–ø–æ–ª–Ω–æ—Ç–∞,–∫–æ–º—Ñ–æ—Ä—Ç,–∑–∞–ª–∏–≤–∫–∏,–æ–±–º–µ–Ω,–ø—Ä–∞–∑–¥–Ω–∏–∫,—É—Å–ø–µ—Ö,–Ω–µ–±–æ,—Ü–≤–µ—Ç—É—â–∏–π,–ø—Ä–æ—Å–≤–µ—Ç–ª–µ–Ω–∏–µ,—Å–≤–æ–±–æ–¥–∞,–≤–µ—Å–µ–ª—å–µ,—Ç–∞–Ω—Ü—ã,–æ—Ç–¥—ã—Ö,–æ—Ç–≤–ª–µ—á–µ–Ω–∏–µ,—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–µ,–∏–≥—Ä–∏–≤–æ—Å—Ç—å,–≤–µ—Å–µ–ª—å–µ,–≤–µ—Å–µ–ª–æ—Å—Ç—å,—Ä–∞–¥–æ—Å—Ç—å,–∏–≥—Ä—ã,–ø—Ä–∞–∑–¥–Ω–∏–∫,—à—É—Ç–∫–∏,–≤–µ—Å–µ–ª—å–µ,—Å–º–µ—Ö,—à—É–º,—Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä,–ø–µ—Ç—å,–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è,—Ñ–µ—è,—Ö–ª–æ–ø,–ø–æ–±–µ–¥–∞,–æ–±–º–µ–Ω zabivaka,–≤—ã–∏–≥—Ä—ã—à,–∏–≥—Ä–∞,–ø—Ä–∞–∑–¥–Ω–∏–∫,–∏–≥—Ä—ã,–±–µ–∑—É–º–∏–µ,—Ñ–µ–Ω–æ–º–µ–Ω–∞–ª—å–Ω–æ–µ,–±–ª–∞–≥–æ–¥–∞—Ä–Ω—ã–º,—Å—á–∞—Å—Ç–ª–∏–≤—ã–π,–ø—Ä–∞–∑–¥–Ω–æ–≤–∞—Ç—å,—á–∞—à–∫–∏,–±–∞—Ä,–≤—ã–∏–≥—Ä–∞—Ç—å\".split(\",\"),\n",
    "                     \"hope\": \"üôè,–ø—Ä–æ—Å—Ç–∏—Ç–µ,–º–æ–ª–∏—Ç–µ—Å—å,–æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã,–ø–æ–∑–∏—Ç–∏–≤–Ω—ã,–ø–æ–∑–∏—Ç–∏–≤–Ω—ã,—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å,–±—É–¥—É—â–µ–µ,–±–µ–∑—Ä–∞—Å—Å—É–¥—Å—Ç–≤–æ,–∏–¥–µ–∞–ª–∏–∑–º,—Ä–µ–∞–ª–∏–∑–º,—Å—á–∞—Å—Ç—å–µ,—Ä–∞–¥–æ—Å—Ç—å,–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç,–∂–∏–∑–Ω–µ–Ω–Ω–æ—Å—Ç—å,–ø—Ä–æ–≥—Ä–µ—Å—Å,—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ,—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å,–≤–µ—Ä–∞,–¥–∏–Ω–∞–º–∏—á–Ω–æ—Å—Ç—å,–∑–∞–±–æ—Ç–∞,–Ω–∞—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å,—ç–π—Ñ–æ—Ä–∏—è,–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π,–≤–∞—Ä–∏–∞–Ω—Ç,–≤–æ–∑–º–æ–∂–Ω–æ,—Ä–µ–ª—å–µ—Ñ,–∑–∞–±—ã–≤—á–∏–≤–æ—Å—Ç—å,–∞–±—Å—Ç—Ä–∞–∫—Ü–∏—è,—Ä–∞—Å—Å–ª–∞–±–∏—Ç—å—Å—è,—Ö–æ—Ç–∏—Ç–µ,–Ω–∞–¥–µ–∂–¥–∞,–≤–ª–∞—Å—Ç—å,—É—Å–ø–µ—Ö,–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å,–±—É–¥—É—â–µ–µ,–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏,—Å–æ–≤–µ—Ä—à–µ–Ω–Ω—ã–π,—É–≤–µ—Ä–µ–Ω–Ω—ã–π –≤ —Å–µ–±–µ,—ç–Ω—Ç—É–∑–∏–∞–∑–º,–∞–º–±–∏—Ü–∏–∏,—É–º–∞,–Ω–∞–ø—Ä–∞—Å–Ω–æ,–ø–æ–¥–æ–∂–¥–∏,—Ä–µ–ª–∏–∑,—Å–≤–µ—á–µ–Ω–∏–µ,–º—É–∂–µ—Å—Ç–≤–æ,–ª—É—á—à–µ –≤—Å–µ–≥–æ,–ø–æ–±–µ–¥–∞,–∂–µ–ª–∞–Ω–∏–µ –æ—Ç–¥–∞–≤–∞—Ç—å,–∂–µ–ª–∞–Ω–∏–µ,–≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ,–ø–æ—Å–ª–µ–¥–Ω–µ–µ,–≤—Ä–µ–º—è,—É—à–µ–ª –≤ –æ—Ç—Å—Ç–∞–≤–∫—É,—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ,–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ,–≤–æ–∑—Ä–æ–¥–∏—Ç—å—Å—è,–º–µ—á—Ç—ã,–≤–µ—Ä–∞,—Ç—Ä–∞–≤–º—ã,–ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã,–ø–æ–¥–∏—É–º–∞,—Ç–∞–ª–∞–Ω—Ç,—Ü–µ–ª—å,—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ —Å–µ–±–µ,–∏—Å—Ü–µ–ª–µ–Ω–∏–µ,–¥–∞—Ç—å,—Å–µ–∑–æ–Ω,—Ä–µ—à–∞—é—â–∏–π,–≤—ã–±—Ä–∞–Ω–Ω—ã–π,—É–¥–∞—á–∏,–ª–∞—Å–∫–∞,—Å–æ–≥–ª–∞—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ,—Ö—Ä–∞–Ω–∏—Ç–µ–ª—å,–Ω–µ–ø–æ–∫–æ–ª–µ–±–∏–º–æ–µ,–Ω–∞–π—Ç–∏,—Å–æ—Ö—Ä–∞–Ω–∏—Ç—å,–≤—Ä–µ–º—è,–∂–∏–∑–Ω—å,–ø–æ–±–µ–¥—ã,–≤–æ—Å–∫—Ä–µ—Å–∏—Ç—å,—Å—Ç—Ä–µ–º–ª–µ–Ω–∏–µ,—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å,—É—Ç–µ—à–µ–Ω–∏–µ,–≤–µ—Ä—É,–≤–µ—Ä–æ–∏—Å–ø–æ–≤–µ–¥–∞–Ω–∏–µ,–≤—Ä–µ–º—è –¥–æ—Å—Ç–∞–≤–∫–∏,–ª–µ—Å—Ç–Ω–æ,–ø–∞—É–∑—É,–ø—Ä–æ–≥–Ω–æ–∑,—Å–ª–µ–¥—É—é—â–µ–µ,–ø—Ä–æ–µ–∫—Ç,–æ–±–µ—â–∞–Ω–∏–µ,–æ–∂–∏–¥–∞–Ω–∏–µ,–∏–ª–ª—é–∑–∏—è,–±–∞–Ω–¥—É—Ä–∞,–∂–∏–∑–Ω—å,–º–∏–ª–æ—Å—Ç—å,–æ–±–µ—â–∞–Ω–∏–µ,–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å,—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å,–∂–µ–ª–∞–Ω–∏–µ,—É—Å–∏–ª–µ–Ω–∏–µ,—Ñ–ª–∞–≥,–±–æ–≥,—Å–≤–µ—Ç,–Ω–∞–ø—Ä–∞—Å–Ω–æ,–ø—Ä–æ–≥—Ä–µ—Å—Å,–≤–µ—Ä–∞,–ø—Ä–∏–∫–æ—Ä–º,–ø—Ä–∏–º–µ—Ç–∞,–ø—Ä–µ–∑—É–º–ø—Ü–∏—è,–ø–µ—á–∞–ª—å,—ç–Ω—Ç—É–∑–∏–∞–∑–º,—Ç–µ—Ä–ø–µ–ª–∏–≤–∞—è,—É—Ç–µ—à—É,–ø–æ–ª–Ω–æ—Ç–∞,—Å—Ç—Ä–∞—Ö–æ–≤–∞–Ω–∏–µ,–∫–æ–Ω –°–æ–ª–∏–Ω–≥,—Ü–µ–ª–µ—É—Å—Ç—Ä–µ–º–ª–µ–Ω–Ω–æ—Å—Ç—å,–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å,–º–ª–∞–¥–µ–Ω–µ—Ü,–∏–Ω—Ç—É–∏—Ü–∏—è,–ø—Ä–æ–≥–Ω–æ–∑,–ø—Ä–æ–µ–∫—Ç,—á—É–≤—Å—Ç–≤–æ,–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å,–ø–æ–∂–µ–ª–∞–Ω–∏–µ,–±–ª–∞–≥–æ—Å–ª–æ–≤–∏—Ç–µ,–≤–µ–Ω—Ç–∏–ª—è—Ç–æ—Ä—ã,–≤–ø–µ—Ä–µ–¥\".split (\",\"),\n",
    "                     \"love\": \"üòç',‚ù§Ô∏è,üíò,üíï,üòò,üòó,–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–∞—è –¥—Ä—É–∂–±–∞,—Ç–æ–≤–∞—Ä–∏—â –ø–æ –∫–æ–º–∞–Ω–¥–µ,–ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å,—Å—Ç—Ä–∞—Å—Ç—å,–ª—é–±–æ–≤—å,–ø–æ—Ü–µ–ª—É–π,–ø—Ä–µ–¥–∞–Ω–Ω–æ—Å—Ç—å,–∫—Ä–∞—Å–æ—Ç–∞,—Å–æ—Å—Ç—Ä–∞–¥–∞–Ω–∏–µ,–ø—Ä–∏—Ç—è–∂–µ–Ω–∏–µ,—Å—á–∞—Å—Ç—å–µ,—É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ,—Å–µ—Ä–¥—Ü–µ,—Ä–æ–º–∞–Ω—Ç–∏–∫–∞,–ø–æ–∫–ª–æ–Ω–µ–Ω–∏–µ,–ø–µ–Ω–∏–µ,–±—Ä–∞—Ç—Å—Ç–≤–æ,—Å–µ—Ä–¥–µ—á–Ω—ã–π,–ø—Ä–µ–¥–∞–Ω–Ω–æ—Å—Ç—å,–±–æ–≥,–≤–µ—Ä–Ω–æ—Å—Ç—å,–ø–ª–∞–º—è,–∞–ª—å—Ç—Ä—É–∏–∑–º,–¥—É—à–∞,–ø–µ—á–∞–ª—å,–ø–µ—Å–Ω—è,–∂–µ–Ω–∞,–º—É–∂,–¥–µ–ª–æ,–≤–µ—Ä–Ω–æ—Å—Ç—å,–∂–µ—Ä—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å,–¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π,Juliet,–∏–¥–µ–∞–ª,–¥—Ä—É–∑—å—è,–∞–º–æ—Ä,–æ–±—ä—è—Ç–∏–µ,–¥–µ–≤—É—à–∫–∞,–±–µ–∑—É–º–Ω–æ,–º–∞–º–∞,–≤–æ—Å—Ö–∏—â–µ–Ω–∏–µ,—â–µ–¥—Ä–æ—Å—Ç—å,—É–≤–∞–∂–µ–Ω–∏–µ,—É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ,–∑–∞–¥–æ—Ä,–±–µ—Å–∫–æ–Ω–µ—á–Ω—ã–µ,–∫—Ä–∞—Å–∏–≤—ã–π,—Å—ã–Ω,–æ—á–∞—Ä–æ–≤–∞—Ç–µ–ª—å–Ω—ã,–ø—Ä–µ–¥–∞–Ω–Ω–æ—Å—Ç—å,–ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å,—Å–ª–∏—è–Ω–∏–µ,—Å–µ—Å—Ç—Ä–∞,—Ä–µ–±–µ–Ω–æ–∫,–≤–æ–∑–≤—ã—à–µ–Ω–∏–µ,–∑–∞–º–µ—á–∞—Ç–µ–ª—å–Ω—ã–π,–æ–±—ä–µ–¥–∏–Ω–∏—Ç—å—Å—è,–±–µ–∑—É–º–Ω–æ,—Å—Ç—Ä–∞—Å—Ç—å,–≤–∑–∞–∏–º–Ω–æ—Å—Ç—å,—Å—Ç—Ä–∞—Å—Ç—å,–±–µ–∑—É–º–∏–µ,–±—Ä–µ–¥,—Å—Ç—Ä–∞—Å—Ç—å,–∑—Ä–µ–ª–∏—â–Ω—ã–µ,–Ω–∞—Ä–∫–æ–º–∞–Ω–∏—è,—É–≤–ª–µ—á–µ–Ω–∏—è,—ç–Ω—Ç—É–∑–∏–∞–∑–º,—ç–º–æ—Ü–∏—è,—Å–∫–ª–æ–Ω–Ω–æ—Å—Ç—å,–æ–≥–æ–Ω—å,—Ä–æ–º–∞–Ω—Ç–∏—á–Ω—ã–π,–≤–µ–ª–∏–∫–æ–ª–µ–ø–Ω—ã–π,–∏–∑–±—ã—Ç–æ–∫,–æ–≥–æ–Ω—å,—Ç–∞–π–Ω–∞,—Å—Ç—Ä–∞—Å—Ç—å,—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è,–ø–æ—ç–∑–∏—è,—ç–Ω—Ç—É–∑–∏–∞–∑–º,–ø–ª–∞–º—è,—á—É–≤—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å,–∑–∞–±–ª—É–∂–¥–µ–Ω–∏–µ,—Å–æ–∫—Ä—É—à–µ–Ω–∏–µ,–¥—É—Ö,—ç–Ω—Ç—É–∑–∏–∞–∑–º,–Ω–µ–Ω–∞—Å—ã—Ç–Ω—ã–π,–¥–æ—Å—É–≥,–ª—é–±–æ–≤—å,–æ—Ç–Ω–æ—à–µ–Ω–∏—è,—Å–∞–¥–æ–≤–æ–¥—Å—Ç–≤–æ,–ø—Ä–µ–¥–∞–Ω–Ω–æ—Å—Ç—å,—Ç–µ–ø–ª–æ—Ç–∞,–≤–æ–∑–≤—ã—à–µ–Ω–Ω–æ—Å—Ç—å —è—Ä–æ—Å—Ç—å,–º–æ–ª–æ–¥–æ—Å—Ç—å,—á—É–≤—Å—Ç–≤–µ–Ω–Ω—ã–π,–æ–≥–Ω–µ–Ω–Ω—ã–π,—Å–µ—Ä–¥—Ü–µ,–¥–∏–∫–∞—è,–ø—Ä–µ–¥–∞–Ω–Ω–æ—Å—Ç—å,–≤–æ–ª–Ω—É—é—â–∏–π,–∂–µ–Ω—â–∏–Ω–∞,–ª—å—Å—Ç–∏—Ç,–Ω–µ–∏—Å—Ç–æ–≤–æ,–ø–æ—Å—Ç—ã–¥–Ω–æ,–¥–µ–ª–æ,–ø–æ—á—Ç—è—Ç—Å—è,–≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è,—Ç—Ä–∞—Ç—è—Ç,—Ä–∞–∑—Ä—É—à–∞—é—Ç,un —Å–æ–∑–Ω–∞–Ω–∏–µ,–≤–æ–∑–≤—ã—à–µ–Ω–Ω–æ–µ,—Ñ–∞–Ω–∞—Ç–∏–∑–º,–ª—é–±–æ–≤—å,–¥—É—à–∞,–∞–ø–ø–µ—Ç–∏—Ç,–≥–æ—Ä—è—â–∞—è –ø–ª–æ—Ç—å,—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ,–ø–æ–∂–∏—Ä–∞–Ω–∏–µ,–∏–≥—Ä–æ–∫,–≤–Ω–µ–∑–∞–ø–Ω—ã–π,–∂–∏–∑–Ω—å,—Ö–æ—Ä–æ–≤–æ–π,–≤–µ—Ä—Ö–æ–≤–∞—è –µ–∑–¥–∞,—É–±–µ–∂–¥–µ–Ω–∏–µ,—Å—Ç—Ä–∞—Å—Ç—å,–∂–µ–ª–∞–Ω–∏–µ,–∏–Ω—Å—Ç–∏–Ω–∫—Ç,—Ö–æ–±–±–∏,—Å–µ–Ω—Ç–∏–º–µ–Ω—Ç–∞–ª—å–Ω—ã–π,—Ç–∞–ª–∞–Ω—Ç–ª–∏–≤—ã–π,—è—Ä–∫–∏–π,—Å–æ–±–∏—Ä–∞—é—Ç,–º–µ—á—Ç–∞–Ω–∏–µ,—Ñ–∞–Ω–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–æ–∂–∞–Ω–∏–µ,–ø—Ä–∏–≤—è–∑–∞–Ω–Ω–æ—Å—Ç—å,–ø–∞–Ω–∏–∫–∞,–≤–æ–ª–Ω–µ–Ω–∏–µ,–ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏–µ,–∏–º–ø—É–ª—å—Å,–≤–æ–ª–Ω–µ–Ω–∏–µ,—ç–Ω—Ç—É–∑–∏–∞–∑–º,—ç–∫—Å—Ç–∞–∑,–ª–∏—Ö–æ—Ä–∞–¥–∫–∞,—É–ø—Ä—è–º—Å—Ç–≤–æ\".split (\",\"),\n",
    "                     \"sadness\": \"üíß,üòø,üôÄ,üò´,üò®,üò≤,üòû,üò©,üò¢,üò™,üò∑,üò≠,üíî,üò¶,–ø–µ—á–∞–ª—å,–±–µ–¥–∞,–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è,–≥—Ä—É—Å—Ç—å,–≥–æ—Ä–µ,—Ç—Ä–∞—É—Ä,–æ—Ç—á–∞—è–Ω–∏–µ,–Ω–æ—Å—Ç–∞–ª—å–≥–∏—è,–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ,–±–æ–ª—å,—Å–ª–µ–∑–∞,–≥—Ä—É—Å—Ç—å,–≥–æ—Ä–µ—á—å,—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ,–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ,–≥—Ä—É—Å—Ç—å,–º–µ–ª–∞–Ω—Ö–æ–ª–∏—è,–¥–µ–ø—Ä–µ—Å—Å–∏—è,—Å–∫–æ—Ä–±—å,—É—Å—Ç–∞–ª–æ—Å—Ç—å,–∑–∞–ø—É—Å—Ç–µ–Ω–∏–µ,–Ω–µ—Å—á–∞—Å—Ç—å–µ,–æ—Ç—Å—Ç–∞–≤–∫–∞,—Ç–∞—Ä–∞–∫–∞–Ω,—É–Ω—ã–Ω–∏–µ,—Å–æ–∂–∞–ª–µ–Ω–∏–µ,–ø–ª–∞—á,–≥–æ—Ä—å–∫–∞—è,–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ,—Å–æ—Å—Ç—Ä–∞–¥–∞–Ω–∏–µ,—É—Ç–µ—à–µ–Ω–∏–µ,–∑–ª–æ–ø–∞–º—è—Ç–Ω–æ—Å—Ç—å,–≥—É–ª—è–Ω–∫–∏,–≥–ª—É–±–æ–∫–∏–π,–±–ª—é–∑,—Å–∏–∑–æ,–ø—Ä–æ—â–∞–π—Ç–µ,—Å–ª–µ–∑–æ—Ç–µ—á–µ–Ω–∏–µ,–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞,–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ,–ø–æ–¥–∞–≤–ª–µ–Ω–Ω–∞—è,–≤—ã—Å—Ç—Ä–µ–ª,–ø–ª–∞—á,–º—Ä–∞—á–Ω–æ–µ,–æ–±–ª–∞–∫–æ,–∞–≥—Ä–µ—Å—Å–∏—è,—Ç–æ—Å–∫–∞,—Å–∫—É–∫–∞,—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ,–æ—Ç—á–∞—è–Ω–∏–µ,–Ω–µ–¥–æ–≤–æ–ª—å–Ω–∞—è,–Ω–µ—É–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏–µ,—É—Å—Ç–∞–ª–æ—Å—Ç—å,—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ,–º—Ä–∞—á–Ω–æ–µ,–ø–µ—á–∞–ª—å,–æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ,–Ω–µ—Å—á–∞—Å—Ç–Ω–æ–µ,–Ω–µ—Å—á–∞—Å—Ç—å–µ,–±–æ–ª–µ–∑–Ω–µ–Ω–Ω–æ–µ,–æ—Ç—á–∞—è–Ω–∏–µ,—Ä–∞–∑—Ä—É—à–∏–ª—Å—è,–±–µ–∑—É—Ç–µ—à–Ω–æ–µ,–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–∏–º–æ–µ,–∑–ª–æ,–º–∏–∑–∞–Ω—Ç—Ä–æ–ø–∏—è,–Ω–∏—â–µ—Ç–∞,–±–µ–¥–Ω–æ—Å—Ç—å,–ª–µ–Ω–æ—Å—Ç—å,–∏–∑–æ–ª—è—Ü–∏—è,–æ–±—â–µ–µ –Ω–µ–¥–æ–º–æ–≥–∞–Ω–∏–µ,–Ω—Ä–∞–≤—Å—Ç–≤–µ–Ω–Ω—ã–µ,–∑–ª–æ–±–∞,—É–Ω—ã–Ω–∏–µ,–ø–µ—á–∞–ª—å,—Å–∫—É–∫–∞, dreadfulness,—Å–∫—É–∫–∞,—Å–º—É—â–µ–Ω–∏–µ,–≥–Ω–æ–π–Ω—ã–π,–∂–∞–¥–Ω–æ—Å—Ç—å,–∏–ø–æ—Ö–æ–Ω–¥—Ä–∏—è,–Ω–µ–≤—ã—Ä–∞–∑–∏–º–æ–µ,—Ç–æ—Å–∫–ª–∏–≤–æ–µ,–º–æ–Ω–æ—Ç–æ–Ω–Ω–æ–µ,–≤—Å–ø–æ–º–∏–Ω–∞–Ω–∏–µ,–ø–∞—Ä–∞–ª–∏–∑–∞—Ç–æ—Ä,–º—É—á–µ–Ω–∏–µ,–æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å,—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ,–ø–ª–æ—Ö–æ–µ,–±–µ–∑–¥–æ–º–Ω–æ–≥–æ,–∫–ª–∞–¥–±–∏—â–µ,–ø–æ–ª–∑—É—á–∞—è,–ª—é—Ç–æ—Å—Ç—å,—Ç—è–∂–µ–ª—ã,—Å—Ç–∞—Ä—ã–π,–≤–æ–∑—Ä–∞—Å—Ç,—É–±–æ–≥–æ,–∂–∞–ª–∫–æ,–ø–µ—Å—Å–∏–º–∏—Å—Ç–∏—á–µ—Å–∫–∏–π,–ø–µ—Å—Å–∏–º–∏–∑–º,–±—É–¥–µ—Ç,–ø–æ—Ä–∞–∂–µ–Ω—á–µ—Å—Ç–≤–æ,–º–µ–ª–∞–Ω—Ö–æ–ª–∏—è,—Å–∫–µ–ø—Ç–∏—Ü–∏–∑–º,–≥–æ—Ä—å–∫–∏–π,–±–æ–ª–µ–∑–Ω–µ–Ω–Ω—ã–π,–æ—Ç—Å—Ç–∞–≤–∫–∞,—Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è,–≥–æ—Ä–µ—á—å,–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ,—Ñ–∞—Ç–∞–ª–∏–∑–º,—Ä–æ–º–∞–Ω—Ç–∏–∑–º,—Å–∏–º–≤–æ–ª–∏–∑–º,–∫–æ–Ω—Ü–µ–ø—Ü–∏—è,—Ä–æ–º–∞–Ω—Ç–∏–∫,—Å–∞–º–æ—É–±–∏–π—Å—Ç–≤–æ,–∏–Ω–¥–∏–≤–∏–¥—É–∞–ª–∏–∑–º,–†–∞–∑–≤—è–∑–∫–∞,–æ—Ç—Ä–µ—á–µ–Ω–∏–µ,–Ω–µ–≥–∞—Ç–∏–≤,–¥–µ–∫–∞–¥–∞–Ω—Å,–ø–∞–Ω–∏—á–µ—Å–∫–∏–π,–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∏–∑–º,–Ω–µ–≤–µ—Ä–∏–µ,–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ,–Ω–µ–≤—Ä–∞—Å—Ç–µ–Ω–∏—è,–Ω–æ—Å—Ç–∞–ª—å–≥–∏—è,–±–µ—Å–ø–æ–∫–æ–π—Å—Ç–≤–æ,—Ç—Ä–∞–≥–∏—á–µ—Å–∫–∏–π,–Ω–∏—â–µ—Ç–∞,–±–µ–∑—Ä–∞–±–æ—Ç–∏—Ü–∞,—Å—É–∏—Ü–∏–¥,–±–µ–¥–Ω—ã–π,–º–µ—Ä—Ç–≤—ã–π,—Å–º–µ—Ä—Ç—å,–∫–ª–∞–¥–±–∏—â–µ,—Å–ª–µ–∑—ã,–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å,–ø–æ—Ç–µ—Ä—Ç—ã–π,–∂–∞–ª–∫–∏–π,–∂–∞–ª—å,–±–æ–ª—å–Ω–æ–π,–ø–æ—Ç–µ—Ä—è—Ç—å\".split (\",\"),\n",
    "                     \"anger\": \"üò†,üò§,üëé,üñï,üò°,üí¢,üî¥,üëä,‚ùó,üíÄ,üòí,—Å—É–µ—Ç–ª–∏–≤–æ—Å—Ç—å,—Ä—É–≥–∞—Ç–µ–ª—å—Å—Ç–≤–æ,–≤–æ—Ä—á–∞–Ω–∏–µ,—á–µ—Ä–µ–ø,–Ω–µ–≥–æ–¥–æ–≤–∞–Ω–∏–µ,—è—Ä–æ—Å—Ç—å,—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ,—Ö–æ–ª–µ—Ä–∏–∫,–Ω–µ–≥–æ–¥–æ–≤–∞–Ω–∏–µ,—è—Ä–æ—Å—Ç—å,–Ω–µ–Ω–∞–≤–∏—Å—Ç—å,–≥–Ω–µ–≤,–∑–ª–æ–±–∞,–º–µ—Å—Ç—å,—è—Ä–æ—Å—Ç—å,–≥–Ω–µ–≤,–≥–Ω–µ–≤,—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ,–≥–æ—Ä–¥–æ—Å—Ç—å,–Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ,—è—Ä–æ—Å—Ç—å,–¥–æ—Å–∞–¥—É –±—É–Ω—Ç,—è—Ä–æ—Å—Ç—å,–≤—Ä–∞–∂–¥–µ–±–Ω–æ—Å—Ç—å,–ø—Ä–µ–∑—Ä–µ–Ω–∏–µ,–∑–ª–æ–±–∞,—É–Ω—ã–Ω–∏–µ,–≥–Ω–µ–≤,–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ,–≤—Å–ø—ã–ª—å—á–∏–≤–æ—Å—Ç—å,—Ä—É–≥–∞—Ç–µ–ª—å—Å—Ç–≤–æ,–≥–æ—Ä–µ—á—å,–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ—Å—Ç—å,–Ω–µ—Ç–µ—Ä–ø–µ–ª–∏–≤–æ—Å—Ç—å,—É–≥—Ä–æ–∑—ã,–≤—Ä–∞–∂–¥–µ–±–Ω–æ—Å—Ç—å,–≤–∑—Ä—ã–≤,—É–Ω–∏–∂–µ–Ω–∏–µ,–Ω–∞—Å–∏–ª–∏–µ,–≥–Ω–µ–≤,–æ—Ç—á–∞—è–Ω–∏–µ,–Ω–∞—Å–∏–ª–∏–µ,–≤–∑—Ä—ã–≤,–º—Å—Ç–∏—Ç—å,—Å–ø–æ—Ç—ã–∫–∞–µ—Ç—Å—è,–∏–∑—É–º–ª–µ–Ω–∏–µ,–∞–≥—Ä–µ—Å—Å–∏—è,–ø—Ä–æ—è–≤–ª–µ–Ω–∏–µ,—á—É–≤—Å—Ç–≤–æ –≤–∏–Ω—ã,–∑–∞–º–æ–∫,–ª–∏–∫–≤–∏–¥–∞—Ü–∏—è,–Ω–µ—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å,–≤—Å–ø—ã–ª—å—á–∏–≤–∞—è,–Ω–∞–∫–∞–∑–∞–≤,–±–µ–∑—É–º–∏–µ,–¥–µ-—é—Ä—É,–ø–æ–¥—Å—Ç—Ä–µ–∫–∞—Ç—å,–≤–æ–∑–±—É–∂–¥–∞–µ—Ç,–≥—Ä–æ–º,–º–æ–ª–Ω–∏–µ–Ω–æ—Å–Ω—ã–π,—Ä–∞–∑–¥—Ä–∞–∂–∞–µ—Ç,–º–∞—Å—Ç–µ—Ä,–¥–µ—Ä—å–º–æ,–≥–ª—É—Ö–æ–π,—è—Ä–æ—Å—Ç–µ–Ω—å,–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–µ,—Ä–∞–∑–¥—Ä–∞–∂–µ–Ω–∏–µ,–ø—É–∑—ã—Ä—å,–∑–∞—Ö–≤–∞—Ç,—Ä–∞–∑–≤—è–∑—ã–≤–∞–Ω–∏–µ,—Ä–∞–∑–¥—Ä–∞–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å,—Ä–∞–∑–¥—Ä–∞–∂–∞—é—â–∞—è,–≤–æ–∑–º—É—â–µ–Ω–Ω–æ–µ,—Ä–µ–ø—Ä–µ—Å—Å–∏—Ä–æ–≤–∞–Ω–æ,–Ω–µ–∏—Å—Ç–æ–≤–æ–µ,–ø—Ä–∏–Ω—è—Ç–∏–µ,—Ä–∞–∑–æ—Ä—É–∂–∏—Ç—å,—Ä–∞–∑–ª–∏–≤,–≤–ª–∏—Ç—å,–∏–∑,–≤—ã—Ç—å,–∏–º–ø—É–ª—å—Å,–≤–æ–∑–º—É—â–µ–Ω–∏–µ,–≤—ã—Ö–æ–¥,—Å—Ç—Ä–∞—à–Ω–æ–µ,–≤—Ä–∞–∂–¥–µ–±–Ω–æ—Å—Ç—å,–º—Å—Ç–∏—Ç–µ–ª—å,–∏–∑–±–∏–≤–∞—è,–Ω–µ—á–µ—Å—Ç–Ω–æ—Å—Ç—å,–∫–æ–Ω–µ—Ü,–ø–æ–∑–æ—Ä,–∑–ª–æ,—Å—Ç—Ä–∞—Ö,–æ—Å–∫–æ—Ä–±–ª—è–ª,–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–µ,–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–µ,–æ—Ç–∫—Ä–æ–≤–µ–Ω–Ω–∞—è,–Ω–∞–∫–∞–∑—ã–≤–∞–µ—Ç,–±–µ–∑–æ–±—Ä–∞–∑–∏–µ,–≥—Ä–µ—Ö,–∂–∞–ª–æ,–∂–∞–¥–Ω–æ—Å—Ç—å,–∂–∂–µ–Ω–∏–µ,–≥–Ω–µ–≤,–Ω–µ–¥–æ—É–º–µ–Ω–∏–µ,–∏–∑–≤–µ—Ä–∂–µ–Ω–∏–µ,–ª–∏—Ö–æ—Ä–∞–¥–∫–∞,—Ç—Ä–µ–ø–µ—Ç–Ω–æ–µ,–±–µ–∑—É–º–∏–µ,–¥–æ–º–æ–≥–∞—Ç–µ–ª—å—Å—Ç–≤–æ,–Ω–µ–≤–æ–∑–¥–µ—Ä–∂–∞–Ω–Ω–æ—Å—Ç—å,–∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç—å,–º–µ–∂–¥–æ–º–µ—Ç–∏–µ,–Ω–µ–¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å,–∫–ª—É–±,—É–≥—Ä–æ–∂–∞—é—â–∞—è,firecr –ê–∫–µ—Ä,—Ä–∞–∑–¥—Ä–∞–∂–∞–µ—Ç—Å—è,–∑–ª–æ–±–Ω—ã–π,–Ω–∞–ø—Ä—è–∂–µ–Ω–∏–µ,–Ω–∞—Å–∏–ª–∏–µ,—Ä—ã—á–∞,—É–≥—Ä–æ–∂–∞—é—â–∏–º,–ø–∞–Ω–∫,–Ω–∞–ø–∞–¥–µ–Ω–∏–µ,–≤–æ–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π,–Ω–µ–Ω–∞–≤–∏—Å—Ç—å,–ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–µ,–∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ,–≤—Ä–∞–∂–¥–µ–±–Ω–æ,–∑–∞–≤–æ–µ–≤–∞—Ç–µ–ª—å,–≤—ã—Å–æ–∫–æ–º–µ—Ä–Ω—ã–π,–Ω–∞–≥–ª—ã–π,–Ω–µ—Ç–µ—Ä–ø–∏–º—ã–º,–≤–∑–ª–æ–º—â–∏–∫,—Ç–æ–Ω,–ø–∞—Å—Å–∏–≤–Ω—ã–π,—Å–∞—Ä–∫–∞—Å—Ç–∏—á–µ—Å–∫–∏–π,–±—Ä—É—Ç–∞–ª—å–Ω—ã–π,—Å–æ—Å—Ç—è–∑–∞—Ç–µ–ª—å–Ω—ã–π,—Ç–µ–º–ø–µ—Ä–∞–º–µ–Ω—Ç,–ø–∏—Ç–±—É–ª—å,–≤–æ–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è,–Ω—ã—Ç—å–µ,–±—Ä–æ—Å–∫–∏–π,–µ–¥–∫–∏–π,–Ω–µ—Ç–µ—Ä–ø–µ–ª–∏–≤—ã–π,–∫–∏—Å–ª—ã–π,–±—É—è–Ω,–±–æ–µ—Ü,–≥–Ω–µ–≤,–≤–æ–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π,–Ω–µ—É–∂–∏–≤—á–∏–≤—ã–π,—Å–≤–∞—Ä–ª–∏–≤—ã–π,–∂–µ—Å—Ç–æ–∫–∏–π,–æ–ø–∞—Å–Ω—ã–π,–æ–ø–∞—Å–Ω—ã–π,–±–æ–π,–±–æ–µ—Ü,—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ,—è—Ä–æ—Å—Ç—å,—Ä–∞–∑–≥–Ω–µ–≤–∞–Ω–Ω—ã–π,–Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω—ã–π,–ø–æ—Ä—ã–≤–∏—Å—Ç—ã–π,–≤—Å–ø—ã–ª—å—á–∏–≤–∞—è,–∑–ª–æ–π,–≤–æ–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π,–æ–±–∏–∂–∞—è,–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ,–ø—Ä–æ–≤–æ—Ü–∏—Ä—É—è,–¥—Ä–∞—á–ª–∏–≤—ã–π,–±—É—à—É–µ—Ç\".split (\",\"),\n",
    "                     \"neutral\":\"\",\n",
    "                     \"joy/hope\":\"\",\n",
    "                     \"love/sadness\":\"\"\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input: Dictionnaire de champ lexicaux √† stemmatiser. \n",
    "#Output: Dictionnaire dict_sentiment_stem ou l'on a pris la racine des mots de dict_sentiment\n",
    "def stem_lexical(dic,stemmer):  \n",
    "    dict_sentiment_stem = {\"joy\":\"\",\"hope\":\"\",\"love\":\"\",\"sadness\":\"\",\"anger\":\"\",\"neutral\":\"\",\"joy/hope\":\"\",\"love/sadness\":\"\"}\n",
    "    for keys in dic:\n",
    "        liste = []\n",
    "        for values in dic[keys]:\n",
    "            values2 = emoji.demojize(values)\n",
    "            liste.append(stemmer.stem(values2))\n",
    "        dict_sentiment_stem[keys] = set(liste)\n",
    "    return dict_sentiment_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sentiment_en_stem=stem_lexical(dict_sentiment_en,stemmer_en)\n",
    "dict_sentiment_ru_stem=stem_lexical(dict_sentiment_ru,stemmer_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_sentiment_en_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_lexical_word(lang,dico_stem):\n",
    "    print(\"\\nLongueur des champs lexicaux \"+lang)\n",
    "    for k in dico_stem:\n",
    "        print(k+\": \"+str(len(dico_stem[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Longueur des champs lexicaux english\n",
      "joy: 83\n",
      "hope: 116\n",
      "love: 133\n",
      "sadness: 129\n",
      "anger: 157\n",
      "neutral: 0\n",
      "joy/hope: 0\n",
      "love/sadness: 0\n",
      "\n",
      "Longueur des champs lexicaux russian\n",
      "joy: 78\n",
      "hope: 113\n",
      "love: 126\n",
      "sadness: 128\n",
      "anger: 144\n",
      "neutral: 0\n",
      "joy/hope: 0\n",
      "love/sadness: 0\n"
     ]
    }
   ],
   "source": [
    "length_lexical_word(\"english\",dict_sentiment_en_stem)\n",
    "length_lexical_word(\"russian\",dict_sentiment_ru_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(tweet, dic_sent):\n",
    "    dico = {\"joy\":0,\"hope\":0,\"love\":0,\"sadness\":0,\"anger\":0,\"neutral\":0,\"joy/hope\":0,\"love/sadness\":0}\n",
    "    for key in dico:\n",
    "        for mot in tweet:\n",
    "            if mot in dic_sent[key]:\n",
    "                dico[key]+=1\n",
    "    if (dico[\"joy\"] == 0 and dico[\"hope\"]  == 0 and dico[\"love\"] == 0 and dico[\"sadness\"] == 0 and dico[\"anger\"]== 0 ):\n",
    "        dico[\"neutral\"] +=10\n",
    "    if (dico[\"joy\"] == dico[\"hope\"]):\n",
    "        dico[\"joy/hope\"] = dico[\"joy\"]+dico[\"hope\"]\n",
    "    if (dico[\"sadness\"] == dico[\"love\"]):\n",
    "        dico[\"love/sadness\"] = dico[\"love\"]+dico[\"sadness\"]\n",
    "    return dico\n",
    "\n",
    "#Input: tweet √† pr√©dire\n",
    "#Output: r√©sultat de count(tweet stemmatis√©e,dic,stopwords)\n",
    "def predict_sentiment(tweet0, dic,stopwords,stemmer):\n",
    "    a = lemmatiz(tweet0)\n",
    "    liste = delete_stw(a,stopwords)\n",
    "    a = stem_tweet(a,stemmer)\n",
    "    return count(a,dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the activist kiril kotov was arrested for 15 days for picketing against world cup 2018 https://t.co/77mvunskri via‚Ä¶ https://t.co/dfkwekquga\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'hope': 0,\n",
       " 'joy': 1,\n",
       " 'joy/hope': 0,\n",
       " 'love': 0,\n",
       " 'love/sadness': 0,\n",
       " 'neutral': 0,\n",
       " 'sadness': 0}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_pred=list_low_en[1]\n",
    "print(tweet_pred)\n",
    "senti=predict_sentiment(tweet_pred, dict_sentiment_en_stem,stw_en,stemmer_en)\n",
    "senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–æ—Ç–∫—Ä—ã–≤–∞–µ–º —á–µ–º–ø–∏–æ–Ω–∞—Ç –º–∏—Ä–∞ –¥–µ—Ä–∂–∏—Ç–µ—Å—å (@ –ª–∏–≥–∞ —Å—Ç–∞–≤–æ–∫(–º–æ—Å–∫–æ–≤—Å–∫–∏–π)) https://t.co/yf3mk1djwn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'anger': 0,\n",
       " 'hope': 0,\n",
       " 'joy': 1,\n",
       " 'joy/hope': 0,\n",
       " 'love': 0,\n",
       " 'love/sadness': 0,\n",
       " 'neutral': 0,\n",
       " 'sadness': 0}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_pred=list_low_ru[1]\n",
    "print(tweet_pred)\n",
    "senti_ru=predict_sentiment(tweet_pred, dict_sentiment_ru_stem,stw_ru,stemmer_ru)\n",
    "senti_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy: 714\n",
      "hope: 151\n",
      "love: 120\n",
      "sadness: 66\n",
      "anger: 23\n",
      "neutral: 1220\n",
      "joy/hope: 68\n",
      "love/sadness: 3\n"
     ]
    }
   ],
   "source": [
    "#Code test, pr√©dit toutes les tweets dans list_low_en\n",
    "#Output: Dictionnaire => sentiment : ids des tweets qui ont ce sentiment\n",
    "\n",
    "dico_test = {\"joy\":[],\"hope\":[],\"love\":[],\"sadness\":[],\"anger\":[],\"neutral\":[],\"joy/hope\":[],\"love/sadness\":[]}\n",
    "\n",
    "for i in range(0,len(list_low_en)):\n",
    "    tweet_pred=list_low_en[i]\n",
    "    senti_en=predict_sentiment(tweet_pred, dict_sentiment_en_stem,stw_en,stemmer_en)\n",
    "    dico_test[max(senti_en.items(), key=operator.itemgetter(1))[0]].append(i)\n",
    "    #Affiche pour chaque sentiment le nombre de tweets qui ont ce sentiment\n",
    "for k in dico_test:\n",
    "    print(k+\": \"+str(len(dico_test[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joy: 752\n",
      "hope: 399\n",
      "love: 378\n",
      "sadness: 88\n",
      "anger: 93\n",
      "neutral: 7077\n",
      "joy/hope: 162\n",
      "love/sadness: 8\n"
     ]
    }
   ],
   "source": [
    "#Code test, pr√©dit toutes les tweets dans list_low_en\n",
    "#Output: Dictionnaire => sentiment : ids des tweets qui ont ce sentiment\n",
    "\n",
    "dico_test = {\"joy\":[],\"hope\":[],\"love\":[],\"sadness\":[],\"anger\":[],\"neutral\":[],\"joy/hope\":[],\"love/sadness\":[]}\n",
    "\n",
    "for i in range(0,len(list_low_ru)):\n",
    "    tweet_pred=list_low_ru[i]\n",
    "    senti_ru=predict_sentiment(tweet_pred, dict_sentiment_ru_stem,stw_ru,stemmer_ru)\n",
    "    dico_test[max(senti_ru.items(), key=operator.itemgetter(1))[0]].append(i)\n",
    "    #Affiche pour chaque sentiment le nombre de tweets qui ont ce sentiment\n",
    "for k in dico_test:\n",
    "    print(k+\": \"+str(len(dico_test[k])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standing up @ saint petersburg, russia https://t.co/u9y7anqw9v\n",
      "\n",
      "principal sentiment: joy\n",
      "{'joy': 1, 'hope': 0, 'love': 0, 'sadness': 0, 'anger': 0, 'neutral': 0, 'joy/hope': 0, 'love/sadness': 0}\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Affiche le tweet et le sentiment associ√©\n",
    "tweet_pred_en=list_low_en[i]\n",
    "print(str(tweet_pred_en)+\"\\n\")\n",
    "senti_en=predict_sentiment(tweet_pred_en, dict_sentiment_en_stem,stw_en,stemmer_en)\n",
    "print(\"principal sentiment: \"+max(senti_en.items(), key=operator.itemgetter(1))[0])\n",
    "print(senti_en)\n",
    "print(i)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–æ—Ç–∫—Ä—ã–≤–∞–µ–º —á–µ–º–ø–∏–æ–Ω–∞—Ç –º–∏—Ä–∞ –¥–µ—Ä–∂–∏—Ç–µ—Å—å (@ –ª–∏–≥–∞ —Å—Ç–∞–≤–æ–∫(–º–æ—Å–∫–æ–≤—Å–∫–∏–π)) https://t.co/yf3mk1djwn\n",
      "\n",
      "principal sentiment: joy\n",
      "{'joy': 1, 'hope': 0, 'love': 0, 'sadness': 0, 'anger': 0, 'neutral': 0, 'joy/hope': 0, 'love/sadness': 0}\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Affiche le tweet et le sentiment associ√©\n",
    "tweet_pred_ru=list_low_ru[i]\n",
    "print(str(tweet_pred_ru)+\"\\n\")\n",
    "senti_ru=predict_sentiment(tweet_pred_ru, dict_sentiment_ru_stem,stw_ru,stemmer_ru)\n",
    "print(\"principal sentiment: \"+max(senti_ru.items(), key=operator.itemgetter(1))[0])\n",
    "print(senti_ru)\n",
    "print(i)\n",
    "i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_senti_en = list()\n",
    "for i in range(0,len(list_low_en)):\n",
    "    tweet_pred_en=list_low_en[i]\n",
    "    senti_en=predict_sentiment(tweet_pred_en, dict_sentiment_en_stem,stw_en,stemmer_en)\n",
    "    list_senti_en.append(max(senti_en.items(), key=operator.itemgetter(1))[0])\n",
    "    dict_id_sent_en = dict(zip(list_good_id_en,list_senti_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_id_sent_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_senti_ru = list()\n",
    "for i in range(0,len(list_low_ru)):\n",
    "    tweet_pred_ru=list_low_ru[i]\n",
    "    senti_ru=predict_sentiment(tweet_pred_ru, dict_sentiment_ru_stem,stw_ru,stemmer_ru)\n",
    "    list_senti_ru.append(max(senti_ru.items(), key=operator.itemgetter(1))[0])\n",
    "    dict_id_sent_ru = dict(zip(list_good_id_ru,list_senti_ru))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sent_pred = list()\n",
    "for e in dict_id_sent_en.values():\n",
    "    list_sent_pred.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sent_pred_ru = list()\n",
    "for e in dict_id_sent_ru.values():\n",
    "    list_sent_pred_ru.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_en = []\n",
    "lon_en = []\n",
    "for i in range(0, len(coord_en)):\n",
    "    lon_en.append(coord_en[i][1])\n",
    "    lat_en.append(coord_en[i][0])\n",
    "\n",
    "df_lat_en = pd.DataFrame({'Lat': lat_en})\n",
    "df_lon_en = pd.DataFrame({'Lon': lon_en})\n",
    "result_en = pd.concat([df_lat_en, df_lon_en], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_ru = []\n",
    "lon_ru = []\n",
    "for i in range(0, len(coord_ru)):\n",
    "    lon_ru.append(coord_ru[i][1])\n",
    "    lat_ru.append(coord_ru[i][0])\n",
    "\n",
    "df_lat_ru = pd.DataFrame({'Lat': lat_ru})\n",
    "df_lon_ru = pd.DataFrame({'Lon': lon_ru})\n",
    "result_ru = pd.concat([df_lat_ru, df_lon_ru], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2365"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coord_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8957"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(coord_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_en.to_csv(\"gps_fifa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ru.to_csv(\"gps_fifa_ru.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_en = []\n",
    "for i in range(0,len(result_en)):   \n",
    "    gps_en.append([result_en.Lat[i], result_en.Lon[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_ru = []\n",
    "for i in range(0,len(result_ru)):   \n",
    "    gps_ru.append([result_ru.Lat[i], result_ru.Lon[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_sent = []\n",
    "def color_map(sentiment):\n",
    "    for i in range(len(sentiment)):\n",
    "        if sentiment[i] == \"neutral\":\n",
    "            color_sent.append(str(\"grey\"))\n",
    "        elif sentiment[i] == \"joy\":\n",
    "            color_sent.append(str(\"orange\"))\n",
    "        elif sentiment[i] == \"anger\":\n",
    "            color_sent.append(str(\"crimson\"))\n",
    "        elif sentiment[i] == \"love\":\n",
    "            color_sent.append(str(\"red\"))\n",
    "        elif sentiment[i] == \"sadness\":\n",
    "            color_sent.append(str(\"black\"))\n",
    "        elif sentiment[i] == \"hope\":\n",
    "            color_sent.append(str(\"yellow\"))  \n",
    "        elif sentiment[i] == \"joy/hope\":\n",
    "            color_sent.append(str(\"green\")) \n",
    "        elif sentiment[i] == \"love/sadness\":\n",
    "            color_sent.append(str(\"purple\")) \n",
    "    return color_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = color_map(list_sent_pred)\n",
    "color_ru = color_map(list_sent_pred_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapit = None\n",
    "fond = r'http://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}.png'\n",
    "mapit = folium.Map(location=[59.9386300,30.3141300], zoom_start=6, tiles=fond, attr='√Ç¬© OpenStreetMap √Ç¬© CartoDB')\n",
    "\n",
    "for i in range(len(gps_en)):\n",
    "    \n",
    "    folium.CircleMarker( location=[ gps_en[i][0], gps_en[i][1] ], radius = 4,  color = color[i], fill = True, fill_color = color[i]).add_to( mapit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapit.save(\"map3.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thu Jun 14 11:46:36 +0000 2018'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1][\"created_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapit = None\n",
    "fond = r'http://{s}.basemaps.cartocdn.com/light_all/{z}/{x}/{y}.png'\n",
    "mapit = folium.Map(location=[59.9386300,30.3141300], zoom_start=6, tiles=fond, attr='√Ç¬© OpenStreetMap √Ç¬© CartoDB')\n",
    "\n",
    "for i in range(len(gps_ru)):\n",
    "    \n",
    "    folium.CircleMarker( location=[ gps_ru[i][0], gps_ru[i][1] ], radius = 4,  color = color_ru[i], fill = True, fill_color = color_ru[i]).add_to( mapit )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapit.save(\"map_ru.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
